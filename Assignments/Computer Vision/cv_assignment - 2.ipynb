{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a02828",
   "metadata": {},
   "source": [
    "# cv_assignment - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca15f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nA convolutional neural network is a feed-forward neural network that is generally used to analyze visual images by processing data with grid-like topology.\\nIt's also known as a ConvNet. A convolutional neural network is used to detect and classify objects in an image.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1\n",
    "\"\"\"\n",
    "A convolutional neural network is a feed-forward neural network that is generally used to analyze visual images by processing data with grid-like topology.\n",
    "It's also known as a ConvNet. A convolutional neural network is used to detect and classify objects in an image.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "148bb3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A DNN refactoring defines the transformation of the DNN's architecture,\\nthe number and size of its layers, and the distillation of the learned relationships between the input features \\nand function outputs of the original to train the transformed network\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2\n",
    "\"\"\"A DNN refactoring defines the transformation of the DNN's architecture,\n",
    "the number and size of its layers, and the distillation of the learned relationships between the input features \n",
    "and function outputs of the original to train the transformed network\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cfb0a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFlattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector. \\nThe flattened matrix is fed as input to the fully connected layer to classify the image\\n\\n>> No, this isn't specific to transfer learning. It is used over feature maps in the classification layer,\\nthat is easier to interpret and less prone to overfitting than a normal fully connected layer\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3\n",
    "\"\"\"\n",
    "Flattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector. \n",
    "The flattened matrix is fed as input to the fully connected layer to classify the image\n",
    "\n",
    ">> No, this isn't specific to transfer learning. It is used over feature maps in the classification layer,\n",
    "that is easier to interpret and less prone to overfitting than a normal fully connected layer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0990d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNCHW stands for: \\nbatch N, channels C, depth D, height H, width W.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4\n",
    "\"\"\"\n",
    "NCHW stands for: \n",
    "batch N, channels C, depth D, height H, width W.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa55e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe main principle is that a stack of three 3×3 conv. layers are similar to a single 7×7 layer.\\nAnd maybe even better! Because they use three non-linear activations in between (instead of one), which makes the function more discriminative\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5\n",
    "\"\"\"\n",
    "The main principle is that a stack of three 3×3 conv. layers are similar to a single 7×7 layer.\n",
    "And maybe even better! Because they use three non-linear activations in between (instead of one), which makes the function more discriminative\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5e00389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIt is the region in the input space that a particular CNN's feature is affected by. \\nMore informally, it is the part of a tensor that after convolution results in a feature.\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6\n",
    "\"\"\"\n",
    "It is the region in the input space that a particular CNN's feature is affected by. \n",
    "More informally, it is the part of a tensor that after convolution results in a feature.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ba94fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwe have a 2-dilated 3x3 convolution that is applied in the output of layer which is a normal convolution.\\nAs a result,each element in the 2 coupled layers now has a receptive field of 7×7. If we studied 2-dilated conv alone the receptive field would be simply 5x5 with the same number of parameters.\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7\n",
    "\"\"\"\n",
    "we have a 2-dilated 3x3 convolution that is applied in the output of layer which is a normal convolution.\n",
    "As a result,each element in the 2 coupled layers now has a receptive field of 7×7. If we studied 2-dilated conv alone the receptive field would be simply 5x5 with the same number of parameters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3fb119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA color image is usually represented as a 3D tensor (RGB)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8\n",
    "\"\"\"\n",
    "A color image is usually represented as a 3D tensor (RGB)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75cb832c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\neach channel is individually convoluted and then combined to form a pixel.\\nThis is how blurring operation works. In convolution, kernels weights for each channel are different \\nand we add the 3 channels together to produce a single channels output.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9\n",
    "\"\"\"\n",
    "each channel is individually convoluted and then combined to form a pixel.\n",
    "This is how blurring operation works. In convolution, kernels weights for each channel are different \n",
    "and we add the 3 channels together to produce a single channels output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf64ddd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
