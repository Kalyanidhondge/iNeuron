{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902d64a7",
   "metadata": {},
   "source": [
    "# cv_assignment - 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "536e45af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCovariate shift occurs when the distribution of variables in the training data is different to real-world or testing data\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1\n",
    "\"\"\"\n",
    "Covariate shift occurs when the distribution of variables in the training data is different to real-world or testing data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f05726d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBatch Normalization is an algorithmic method which makes the training of Deep Neural Networks faster and more stable\\nIt consists of normalizing activation vectors from hidden layers using the first and the second statistical moments (mean and variance) of the current batch\\n\\n>> Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2\n",
    "\"\"\"\n",
    "Batch Normalization is an algorithmic method which makes the training of Deep Neural Networks faster and more stable\n",
    "It consists of normalizing activation vectors from hidden layers using the first and the second statistical moments (mean and variance) of the current batch\n",
    "\n",
    ">> Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdfbdacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe LeNet architecture is an excellent first architecture for Convolutional Neural Networks\\nIt has three layers namely, convolutional, pooling, and a fully connected layer\\nLeNet-5 CNN architecture is made up of 7 layers. The layer composition consists of 3 convolutional layers, 2 subsampling layers and 2 fully connected layers.\\nLeNet was used in detecting handwritten cheques by banks based on MNIST dataset\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3\n",
    "\"\"\"\n",
    "The LeNet architecture is an excellent first architecture for Convolutional Neural Networks\n",
    "It has three layers namely, convolutional, pooling, and a fully connected layer\n",
    "LeNet-5 CNN architecture is made up of 7 layers. The layer composition consists of 3 convolutional layers, 2 subsampling layers and 2 fully connected layers.\n",
    "LeNet was used in detecting handwritten cheques by banks based on MNIST dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb7387c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThe Alexnet has eight layers with learnable parameters. \\nThe model consists of five layers with a combination of max pooling followed by 3 fully connected layers and they use Relu activation in each of these layers except the output layer.\\nalexNet allows for multi-GPU training by putting half of the model's neurons on one GPU and the other half on another GPU.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4\n",
    "\"\"\"\n",
    "The Alexnet has eight layers with learnable parameters. \n",
    "The model consists of five layers with a combination of max pooling followed by 3 fully connected layers and they use Relu activation in each of these layers except the output layer.\n",
    "alexNet allows for multi-GPU training by putting half of the model's neurons on one GPU and the other half on another GPU.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d97f653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWe can detect vanishing gradient by analysing the kernel weight distribution. There is a vanishing gradient if the weights are falling regularly near zero.\\n\\n>> When there are more layers in the network, the value of the product of derivative decreases until at some point the partial derivative of the \\nloss function approaches a value close to zero, and the partial derivative vanishes. We call this the vanishing gradient problem.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5\n",
    "\"\"\"\n",
    "We can detect vanishing gradient by analysing the kernel weight distribution. There is a vanishing gradient if the weights are falling regularly near zero.\n",
    "\n",
    ">> When there are more layers in the network, the value of the product of derivative decreases until at some point the partial derivative of the \n",
    "loss function approaches a value close to zero, and the partial derivative vanishes. We call this the vanishing gradient problem.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be4ca800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe local normalization tends to uniformize the mean and variance of an image around a local neighborhood.\\nThe local response normalization layer performs a kind of “lateral inhibition” by normalizing over local input regions. \\nIn ACROSS_CHANNELS mode, the local regions extend across nearby channels, but have no spatial extent\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6\n",
    "\"\"\"\n",
    "The local normalization tends to uniformize the mean and variance of an image around a local neighborhood.\n",
    "The local response normalization layer performs a kind of “lateral inhibition” by normalizing over local input regions. \n",
    "In ACROSS_CHANNELS mode, the local regions extend across nearby channels, but have no spatial extent\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d0ec4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nL2 Regularization also known as weight decay is used\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7\n",
    "\"\"\"\n",
    "L2 Regularization also known as weight decay is used\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9876152d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVGG stands for Visual Geometry Group it is a standard deep Convolutional Neural Network (CNN) architecture with multiple layers. \\nThe “deep” refers to the number of layers with VGG-16 or VGG-19 consisting of 16 and 19 convolutional layers. \\nThe VGG architecture is the basis of ground-breaking object recognition models.\\n\\n>> VGG is an innovative object-recognition model that supports up to 19 layers. \\nBuilt as a deep CNN, VGG also outperforms baselines on many tasks and datasets outside of ImageNet. \\nVGG is now still one of the most used image-recognition architectures.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8\n",
    "\"\"\"\n",
    "VGG stands for Visual Geometry Group it is a standard deep Convolutional Neural Network (CNN) architecture with multiple layers. \n",
    "The “deep” refers to the number of layers with VGG-16 or VGG-19 consisting of 16 and 19 convolutional layers. \n",
    "The VGG architecture is the basis of ground-breaking object recognition models.\n",
    "\n",
    ">> VGG is an innovative object-recognition model that supports up to 19 layers. \n",
    "Built as a deep CNN, VGG also outperforms baselines on many tasks and datasets outside of ImageNet. \n",
    "VGG is now still one of the most used image-recognition architectures.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aac87c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVGG- Network is a convolutional neural network model proposed by K. Simonyan and A. Zisserman in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”.\\nThis architecture achieved top-5 test accuracy of 92.7% in ImageNet, which has over 14 million images belonging to 1000 classes\\n\\nThe architecture of VGG uses 13 convolutional layers and 3 fully connected layers. \\nThe convolutional layers in VGG are all 3×3 convolutional layers with a stride size of 1 and the same padding, and the pooling layers are all 2×2 pooling layers with a stride size of 2\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9\n",
    "\"\"\"\n",
    "VGG- Network is a convolutional neural network model proposed by K. Simonyan and A. Zisserman in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”.\n",
    "This architecture achieved top-5 test accuracy of 92.7% in ImageNet, which has over 14 million images belonging to 1000 classes\n",
    "\n",
    "The architecture of VGG uses 13 convolutional layers and 3 fully connected layers. \n",
    "The convolutional layers in VGG are all 3×3 convolutional layers with a stride size of 1 and the same padding, and the pooling layers are all 2×2 pooling layers with a stride size of 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d423995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nL1 and L2 Regularization\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q10\n",
    "\"\"\"\n",
    "L1 and L2 Regularization\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fa8cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
