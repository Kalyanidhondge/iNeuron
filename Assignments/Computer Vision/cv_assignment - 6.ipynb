{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a3e224",
   "metadata": {},
   "source": [
    "# cv_assignment - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf5b351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainable parameters are those which value is modified according to their gradient \\nwhereas non-trainable parameters are those which value is not optimized according to their gradient\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1\n",
    "\"\"\"\n",
    "trainable parameters are those which value is modified according to their gradient \n",
    "whereas non-trainable parameters are those which value is not optimized according to their gradient\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e08aa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndropout is placed on the fully connected layers only because they are the one with the greater number of parameters \\nand thus they're likely to excessively co-adapting themselves causing overfitting\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2\n",
    "\"\"\"\n",
    "dropout is placed on the fully connected layers only because they are the one with the greater number of parameters \n",
    "and thus they're likely to excessively co-adapting themselves causing overfitting\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365bc949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe number of hidden neurons should be between the size of the input layer and the size of the output layer.\\nThe number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3\n",
    "\"\"\"\n",
    "The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d5780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMore than 0 and less than the number of parameters in each filter\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4\n",
    "\"\"\"\n",
    "More than 0 and less than the number of parameters in each filter\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efb83f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point on your problem\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5\n",
    "\"\"\"\n",
    "A traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point on your problem\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db2dc7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nan activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6\n",
    "\"\"\"\n",
    "an activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4606921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNormalization is the process of organizing data in a database.\\nthe reason we normalize the images is to make the model converge faster.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7\n",
    "\"\"\"\n",
    "Normalization is the process of organizing data in a database.\n",
    "the reason we normalize the images is to make the model converge faster.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f43226c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImage augmentation is a technique of altering the existing data to create some more data for the model training process. \\nit is the process of artificially expanding the available dataset for training a deep learning model\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8\n",
    "\"\"\"\n",
    "Image augmentation is a technique of altering the existing data to create some more data for the model training process. \n",
    "it is the process of artificially expanding the available dataset for training a deep learning model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b888303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe most popular form of learning rate annealing is a step decay where the learning rate is reduced by some percentage after a set number of training epochs.\\nwe can establish that it is useful to define a learning rate schedule in which the learning rate is updating during training according to some specified rule.\\n\\n>> Perhaps the simplest learning rate schedule is to decrease the learning rate linearly from a large initial value to a small value. \\nThis allows large weight changes in the beginning of the learning process and small changes or fine-tuning towards the end of the learning process\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9\n",
    "\"\"\"\n",
    "The most popular form of learning rate annealing is a step decay where the learning rate is reduced by some percentage after a set number of training epochs.\n",
    "we can establish that it is useful to define a learning rate schedule in which the learning rate is updating during training according to some specified rule.\n",
    "\n",
    ">> Perhaps the simplest learning rate schedule is to decrease the learning rate linearly from a large initial value to a small value. \n",
    "This allows large weight changes in the beginning of the learning process and small changes or fine-tuning towards the end of the learning process\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a26f637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEarly stopping is a method that allows you to specify an arbitrary large number of training epochs \\nand stop training once the model performance stops improving on a hold out validation dataset\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Early stopping is a method that allows you to specify an arbitrary large number of training epochs \n",
    "and stop training once the model performance stops improving on a hold out validation dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4cd1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
